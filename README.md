# MPI---Sat-Benchmark
# SAT Solver Benchmark Suite

This package provides implementations of DPLL (Complete), CDCL and ProbSAT (Stochastic Local Search) SAT solvers along with benchmarking tools to compare their performance on various SAT instances.

## Getting Started

**CODE WAS GENERATED BY AI**

### Prerequisites
- Python 3.6+
- pandas (for benchmark analysis)
- matplotlib (for generating figures)

### Installation
```bash
# Install required dependencies
pip install pandas matplotlib
```

## Overview

This toolkit includes:

1. **SAT Solvers**: DPLL (complete) and ProbSAT (stochastic local search) implementations
2. **Instance Generator**: For creating random 3-SAT formulas with controlled parameters
3. **Benchmarking Framework**: To systematically compare solvers on various instances
4. **Reporting Tools**: For generating tables and figures suitable for academic papers

## Usage

### Running a Single SAT Instance

```bash
# Solve a DIMACS CNF file using both solvers
python sat_solvers.py your_formula.cnf

# Use only ProbSAT solver
python sat_solvers.py your_formula.cnf --solver probsat

# Generate and solve a random instance with 20 variables
python sat_solvers.py random_20.cnf --generate 20
```

### Running Benchmarks

```bash
# Run benchmark on a directory of CNF files and save results to CSV
python sat_solvers.py instances/vars_20/ --benchmark results.csv

# Generate a batch of random instances
python sat_solvers.py dummy.cnf --batch --sizes 10,20,30,40,50 --instances 5

# Run the complete benchmark suite (generate instances, run benchmarks, create tables)
python benchmark_script.py
```

## Solver Descriptions

### DPLL Solver
- Complete solver (can prove unsatisfiability)
- Features unit propagation
- Uses a variable selection heuristic based on literal occurrences
- Tracks decisions and conflicts for benchmarking

### ProbSAT Solver
- Probabilistic SLS (Stochastic Local Search) solver
- Uses the exponential scoring function from the ProbSAT paper
- Selects variables to flip based on make/break scores
- Supports multiple restarts from random assignments

## File Format

The solvers accept the standard DIMACS CNF format:

```
c Comment line
p cnf <num_vars> <num_clauses>
1 -2 3 0
-1 2 0
...
```

## Example Output

When running a benchmark, the tool produces:

1. CSV file with raw performance data
2. Summary table suitable for inclusion in papers
3. LaTeX-formatted tables
4. Performance scaling figures


